{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow\nprint(tensorflow.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras.utils as ku \nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making data ready to train:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = open('/kaggle/input/poetry/bruno-mars.txt').read()\n\ntokenizer = Tokenizer()\n\ncorpus = data.lower().split(\"\\n\")\n\n\ntokenizer.fit_on_texts(corpus)\ntotal_words = len(tokenizer.word_index) + 1  #adding one for out-of-vocab words\n\n# creating input sequences using list of tokens\ninput_sequences = []\nfor l in corpus:\n\ttoken_list = tokenizer.texts_to_sequences([l])[0]\n\tfor i in range(1, len(token_list)):\n\t\tn_gram_seq = token_list[:i+1]\n\t\tinput_sequences.append(n_gram_seq)\n\n\n# implementing padding\nmax_seq_len = max([len(x) for x in input_sequences])\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre'))\n\npredictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n\n# one hot code\nlabel = ku.to_categorical(label, num_classes=total_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model= Sequential([\n    Embedding(total_words, 100, input_length=max_sequence_len-1), # -1 as the last word is the label\n    Bidirectional(LSTM(150, return_sequences = True)),\n    Dropout(0.2),  #drops 20% of units in a layer\n    LSTM(100),\n    Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n    Dense(total_words, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs= 100\nhistory = model.fit(predictors, label, epochs=num_epochs, verbose=1)\n\n# LAST EPOCH I GOT:\n#Epoch 100/100\n#739/739 [==============================] - 29s 39ms/step - loss: 1.0005 - accuracy: 0.8041","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# To visualize accuracy and loss over the epochs trained:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\naccuracy = history.history['accuracy']\nloss = history.history['loss']\n\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, 'r', label='Training accuracy')\nplt.title('Training accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generating the lyrics:"},{"metadata":{"trusted":true},"cell_type":"code","source":"start_text = \"You know what I want\"\nnum_words = 60  #number of words to generate\n  \nfor _ in range(next_words):\n\ttoken_list = tokenizer.texts_to_sequences([start_text])[0]\n\ttoken_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n\tpredicted = model.predict_classes(token_list, verbose=0)\n\tout_word = \"\"\n\tfor word, index in tokenizer.word_index.items():\n\t\tif index == predicted:\n\t\t\tout_word = word\n\t\t\tbreak\n\tstart_text += \" \" + out_word\nprint(start_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OUTPUT I RECEIVED:**\nYou know what I want you \nwhen you're looking for no replacement \nnow i'm madly in love with you \ni know that you're waiting for \nmore get good for her in their way \noh i love you more today than yesterday \ntonight i wanna jump in the cadillac \nis the night is that \ni will break these chains \nthat bind me \nhappiness will find me"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}